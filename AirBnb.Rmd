---
title: "Fundamentals of Data Analysis"
author: "Final Group Project - Group 4"
date: "30 Sep 2022"
output:
  html_document:
    
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
  pdf_document:
    toc: yes
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
# leave this chunk alone
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```

# R Project

```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
library(kableExtra)
library(performance)
library(patchwork)
library(formattable)
library(car)
library(performance)
library(huxtable)

```

## Exploratory Data Analysis

```{r cities_groups, message=FALSE, warning=FALSE}

listings <- vroom("http://data.insideairbnb.com/italy/emilia-romagna/bologna/2022-06-11/data/listings.csv.gz")%>% 
  #drop variables that contain 'scrape' in their column name
  select(- contains("scrape"))

listings <- listings %>% 
  mutate(price = parse_number(price))

```

```{r EDA_1, echo=FALSE}
glimpse(listings)
skim(listings)

```

How many variables/columns?

```{r EDA_nVariables}

ncol(listings)

```

How many rows/observations?

```{r EDA_nObservations}

nrow(listings)

```

Which variables are numbers?

```{r EDA_numbers}

print(paste("List of the variables that are numbers"))

i=1
for(i in 1:ncol(listings)) {       # for-loop over columns
  if (is.numeric(listings[[i]]) == TRUE)
  {
    print(colnames(listings[i]))
  }
}

```

Which are categorical or factor variables (numeric or character
variables with variables that have a fixed and known set of possible
values)?

```{r EDA_exploreVariables}

maxElements = 10

result <- apply(listings, 2, function(x) length(unique(x)))

print(paste("List of the variables with less than ",maxElements, "elements"))

for(i in 1:ncol(listings)) {       # for-loop over columns
  if(result[colnames(listings)[i]] < maxElements)
  {
    print(colnames(listings)[i])
  }
}

```

What are the correlations between variables? Does each scatterplot
support a linear relationship between variables? Do any of the
correlations appear to be conditional on the value of a categorical
variable?

```{r EDA_correlations}
# exploring correlations with type of hosts 
listings%>%
  select(price, host_id, host_response_time, host_is_superhost, calculated_host_listings_count, calculated_host_listings_count_entire_homes, calculated_host_listings_count_private_rooms, calculated_host_listings_count_shared_rooms)%>%
  ggpairs(alpha = 0.3)

# exploring correlations with parameters of house 
listings%>%
  select(price, accommodates, bedrooms, beds, room_type)%>%
  ggpairs(alpha = 0.3)

#exploring correlations with location
listings%>%
  select(price, neighbourhood_cleansed, latitude, longitude)%>%
  ggpairs(alpha = 0.3)


# exploring correlations with availability
listings%>%
  select(price, minimum_nights, maximum_nights, availability_30, availability_60, availability_90)%>%
  ggpairs(alpha = 0.3)

# exploring correlations with reviews 
listings%>%
  select(price, number_of_reviews, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_value, reviews_per_month)%>%
  ggpairs(alpha = 0.3)

listings %>%
  filter(number_of_reviews>50) %>% 
  group_by(neighbourhood_cleansed) %>%
  summarise(medianPrice = median(price),
            medianRate = median(review_scores_rating, na.rm = TRUE),
            medianBedroom = median(bedrooms, na.rm = TRUE),
            medianMinimumNights = median(minimum_minimum_nights,na.rm = TRUE))

listings %>%
  filter(number_of_reviews>50) %>% 
  group_by(property_type) %>%
  summarise(medianPrice = median(price),
            medianRate = median(review_scores_rating, na.rm = TRUE),
            medianBedroom = median(bedrooms, na.rm = TRUE),
            medianMinimumNights = median(minimum_minimum_nights,na.rm = TRUE),
            totalAccomodations = count(property_type)) %>% 
  filter(totalAccomodations > 5)

listings %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarise(medianPrice = median(price)) %>% 
  mutate(neighbourhood_cleansed = fct_reorder(neighbourhood_cleansed, medianPrice)) %>%
  ggplot(aes(x=medianPrice,y=neighbourhood_cleansed)) +
  geom_col() + 
  theme_classic() +
  labs(title = "Median price in Bologna",
       subtitle = "",
       caption = "Source: http://data.insideairbnb.com/italy/emilia-romagna/bologna/2022-06-11/data/listings.csv.gz") +
  theme(plot.caption = element_text(hjust= 1),
        axis.title.x = element_blank(), 
        axis.title.y = element_blank())

listings %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarise(totalAccomodation = count(neighbourhood_cleansed)) %>% 
  mutate(neighbourhood_cleansed = fct_reorder(neighbourhood_cleansed, totalAccomodation)) %>%
  ggplot(aes(x=totalAccomodation,y=neighbourhood_cleansed)) +
  geom_col() + 
  theme_classic() +
  labs(title = "Number of accomodations in Bologna", 
       subtitle = "", 
       caption = "Source: http://data.insideairbnb.com/italy/emilia-romagna/bologna/2022-06-11/data/listings.csv.gz") +
  theme(plot.caption = element_text(hjust= 1), 
        axis.title.x = element_blank(), #
        axis.title.y = element_blank())

listings %>% 
  filter(price<250) %>% 
  ggplot(aes(price,fill=neighbourhood_cleansed)) + 
  geom_histogram(binwidth = 10) +
  labs(title = "Distribution of price", 
       subtitle = "", 
       caption = "Source: http://data.insideairbnb.com/italy/emilia-romagna/bologna/2022-06-11/data/listings.csv.gz") + 
  theme(plot.caption = element_text(hjust= 1), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank()) +
  scale_fill_discrete(name = "Neighbourhood")


listings %>% 
  filter(number_of_reviews>50) %>% 
  ggplot(aes(review_scores_rating, fill = neighbourhood_cleansed)) +
  geom_density(position = "stack", alpha = 0.4) +
  labs(title = "Ratings with number of reviews more than 50", 
       subtitle = "", 
       caption = "Source: http://data.insideairbnb.com/italy/emilia-romagna/bologna/2022-06-11/data/listings.csv.gz") + 
  theme(plot.caption = element_text(hjust= 1), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank()) +
  scale_fill_discrete(name = "Neighbourhood")

```

*There are the following correlations (\>0.5) among variables:*

-   *calculated_host_listings_count,
calculated_host_listings_count_entire_homes,*

-   *bedrooms, beds, accommodates,*

-   *availability_30, availability_60, availability_90,*

-   *review_scores_rating, review_scores_accuracy,
review_scores_cleanliness, review_scores_checkin,
review_scores_communication, review_scores_value,*

*There are the following linear correlations:*

-   *calculated_host_listings_count,
calculated_host_listings_count_entire_homes*

## Handling missing values (NAs)

Airbnb is most commonly used for travel purposes, i.e., as an
alternative to traditional hotels. We only want to include listings in
our regression analysis that are intended for travel purposes:

Next, we look at the variable property_type. We can use the count
function to determine how many categories there are their frequency.
What are the top 4 most common property types? What proportion of the
total listings do they make up?

```{r property_type_analysis}
listings %>% 
  group_by(property_type) %>% 
  summarise(countType = count(property_type)) %>%
  mutate(percentage = percent(countType/sum(countType))) %>% 
  slice_max(order_by = countType, n=4)

```

Since the vast majority of the observations in the data are one of the
top four or five property types, we would like to create a simplified
version of property_type variable that has 5 categories: the top four
categories and Other. Fill in the code below to create
prop_type_simplified.

```{r prop_type_simplified}

listings <- listings %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit","Entire condo", "Private room in rental unit","Private room in condo") ~ property_type, 
    TRUE ~ "Other"
  ))

listings %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))  

```

What are the most common values for the variable minimum_nights?

```{r commonValueforMinimumNights}

listings%>%
  group_by(minimum_nights)%>%
  summarise(tot_min_night=count(minimum_nights))%>%
  mutate(percentage = percent(tot_min_night/sum(tot_min_night)))%>%  
  arrange(desc(percentage))%>%
  slice_head(n=3)

```

Is there any value among the common values that stands out? What is the
likely intended purpose for Airbnb listings with this seemingly unusual
value for minimum_nights?

```{r lesscommonValueforMinimumNights}

listings%>%
  group_by(minimum_nights)%>%
  summarise(tot_min_night=count(minimum_nights))%>%
  mutate(percentage = percent(tot_min_night/sum(tot_min_night)))%>%  
  arrange(desc(minimum_nights))%>%
  slice_head(n=10)

```

*There are 33 solutions with a minimum nights of at least 30 days
therefore comparable to rentals*

Filter the airbnb data so that it only includes observations with
minimum_nights \<= 4

```{r min_night_4}

listings<- listings%>%
  filter(minimum_nights<=4)

```

## Mapping

Visualisations of feature distributions and their relations are key to
understanding a data set, and they can open up new lines of exploration.
While we do not have time to go into all the wonderful geospatial
visualisations one can do with R, you can use the following code to
start with a map of your city, and overlay all AirBnB coordinates to get
an overview of the spatial distribution of AirBnB rentals. For this
visualisation we use the leaflet package, which includes a variety of
tools for interactive maps, so you can easily zoom in-out, click on a
point to get the actual AirBnB listing for that specific point, etc.

```{r mapping}
leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 2, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)
```

## Regression Analysis

For the target variable Y, we will use the cost for two people to stay
at an Airbnb location for four (4) nights.

Create a new variable called price_4\_nights that uses price, and
accommodates to calculate the total cost for two people to stay at the
Airbnb property for 4 nights. This is the variable Y we want to explain.

```{r createprice_4_nights}
listings <- listings %>% 
  mutate(price_4_nights = price*4)

```

Use histograms or density plots to examine the distributions of
price_4\_nights and log(price_4\_nights). Which variable should you use
for the regression model? Why?

```{r histrogramPrice4Night}
g1 <- listings %>% 
  filter(accommodates>1, price<250) %>% 
  ggplot(aes(price_4_nights)) + 
  geom_histogram(binwidth = 10) +
  labs(title = "Distribution of price of 4 nights", 
       subtitle = "") + 
  theme(plot.caption = element_text(hjust= 1), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank())

g2 <- listings %>% 
  filter(accommodates>1, price<250) %>% 
  ggplot(aes(log(price_4_nights))) + 
  geom_histogram(binwidth = 10) +
  labs(title = "Distribution of log(price) of 4 nights", 
       subtitle = "", 
       caption = "Source: http://data.insideairbnb.com/italy/emilia-romagna/bologna/2022-06-11/data/listings.csv.gz") + 
  theme(plot.caption = element_text(hjust= 1), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank())

g1+g2
```

*We will use the logarithmic scales thus we are interesting in
quantifying the relative change of the price respect to other variables,
and not its absolute value. In this way we can remedy the presence of
many outliers.*

Fit a regression model called model1 with the following explanatory
variables: prop_type_simplified, number_of_reviews, and
review_scores_rating.

```{r regressionmodel1}

model1 <- lm(log(price_4_nights) ~ prop_type_simplified +number_of_reviews + review_scores_rating, data = listings)
msummary(model1)

```

*The total variability explained by this model is low (only 16%) then
variables are not explanatory for cost for 4 nights.*

Interpret the coefficient review_scores_rating in terms of
price_4\_nights.

```{r regressionmodel1a_review}

model1a <- lm(log(price_4_nights) ~ review_scores_rating, data = listings)
msummary(model1a)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An extra review score rating decrease the logarithm of price by 0.06.*

*The total variability explained by this model is very low (only 0.1%)
then scores of reviews is not a significant predictor for cost for 4
nights.*

Interpret the coefficient of prop_type_simplified in terms of
price_4\_nights.

```{r regressionmodel1b_prop_type}

model1b <- lm(log(price_4_nights) ~ prop_type_simplified, data = listings)
msummary(model1b)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An additional unit of the single property types decrease the logarithm
of the price (i.e., Entire rental of unit by 0.07, Other by 0.19,
Private room in condo by 0.68, Private room in rental unit by 0.68)
respect to Tiny room type*

*The total variability explained by this model is low (only 12%) then
property types is not a significant predictor for cost for 4 nights.*

We want to determine if room_type is a significant predictor of the cost
for 4 nights, given everything else in the model. Fit a regression model
called model2 that includes all of the explanantory variables in model1
plus room_type.

```{r regressionmodel2}

model2 <- lm(log(price_4_nights) ~ prop_type_simplified +number_of_reviews + review_scores_rating + room_type, data = listings)
msummary(model2)

```

*The total variability explained by the model2 is better (20%) then
model1 but remain very low so variables are not explanatory for cost for
4 nights.*

```{r regressionmodel2a_room_type}

model2a <- lm(log(price_4_nights) ~ room_type, data = listings)
msummary(model2a)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An additional unit of the type of room increase the logarithm of the
price (i.e., Hotel room by 0.30) or decrease the logarithm of the price
(i.e. Private room of 0.51 and Shared room of 1.32) respect to the type
of Tiny room*

*The total variability explained by this model is low (only 14%) then
property room is not a significant predictor for cost for 4 nights.*

## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you
can extend your analysis

Are the number of bathrooms, bedrooms, beds, or size of the house
(accomodates) significant predictors of price_4\_nights?

```{r regressionmodel3a_bathrooms}

listings<-listings%>%
  separate(bathrooms_text,
           into = c("n_bathrooms", "text_bathrooms"),
           sep = 3)

listings<-listings%>%
  mutate(n_bathrooms=ifelse(test=n_bathrooms=="Hal",
                            yes="0.5",
                            no=n_bathrooms),
         n_bathrooms=ifelse(test=n_bathrooms=="Pri",
                            yes="0.5",
                            no=n_bathrooms),
         n_bathrooms = parse_number(n_bathrooms))

model3a <- lm(log(price_4_nights) ~ n_bathrooms, data = listings)
msummary(model3a)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An extra bathroom increase the logarithm of price by 0.28.*

*The total variability explained by this model is very low (only 4.5%)
then numbers of bathrooms are not a significant predictor for cost for 4
nights.*

```{r regressionmodel3b_bedrooms}

model3b <- lm(log(price_4_nights) ~ bedrooms, data = listings)
msummary(model3b)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An extra bedroom increase the logarithm of the price by 0.31.*

*The total variability explained by this model is very low (only 9%)
then numbers of bathrooms are not a significant predictor for cost for 4
nights.*

```{r regressionmodel3c_beds}

model3c <- lm(log(price_4_nights) ~ beds, data = listings)
msummary(model3c)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An extra bed increase the logarithm of the price by 0.14.*

*The total variability explained by this model is very low (only 7%)
then numbers of bathrooms are not a significant predictor for cost for 4
nights.*

```{r regressionmodel3d_accommodates}

model3d <- lm(log(price_4_nights) ~ accommodates, data = listings)
msummary(model3d)

```

*t-stat value is greater than the 2% and p-value is less than 5% then we
can reject the hypothesis of no difference between variables.*

*An extra accommodates increase the logarithm of price by 0.16.*

*The total variability explained by this model is low (only 16%) then
numbers of bathrooms are not a significant predictor for cost for 4
nights.*

Do superhosts (host_is_superhost) command a pricing premium, after
controlling for other variables?

```{r regressionmodel4_host_is_superhost}

listings%>%
  group_by(host_is_superhost)%>%
  summarise(avg_price=mean(price_4_nights))

model4 <- lm(log(price_4_nights) ~ host_is_superhost, data = listings)
msummary(model4)

```

*The superhosts do not command a pricing premium: mean value of cost for
4 nights is higher for those who are not superhosts.*

*In addition t-stat value is lower than the 2% and p-value is above than
5% then we can accept the hypothesis of no difference between
variables.*

*The condition of being a superhost increase the logarithm of the price
of the room by 0.03 respect if the host is not a superhost.*

*The total variability explained by this model is very low (only 0.01%)
then numbers of bathrooms are not a significant predictor for cost for 4
nights.*

Determine whether location is a predictor of price_4\_nights

```{r regressionmodel6_location}

listings<-listings%>%
  mutate(neighbourhood_simplified=neighbourhood_cleansed)

model6 <- lm(log(price_4_nights) ~ neighbourhood_simplified, data = listings)
msummary(model6)

```

*For some type of neighborhood (i.e., Porto - Saragozza, San Donato -
San Vitale, Santo Stefano) t-stat value is greater than the 2% and
p-value is less than 5% then we can reject the hypothesis of no
difference between variables. For the other types of neighborhood
(Navile, Savena), t-stat value is lower than the 2% and p-value is above
5% then we can accept the hypothesis of no difference between
variables.*

*In addition, an additional unit in some neighborhood increase the
logarithm of price (i.e., Navile by 0.11, Porto - Saragozza by 0.29, San
Donato - San Vitale by 0.15, Santo Stefano by 0.33) and in others
decrease the logarithm of price (Savena by 0.11) respect to Borgo
Panigale - Reno.*

*The total variability explained by this model is very low (only 3%)
then property types is not a significant predictor for cost for 4
nights.*

## Diagnostics, collinearity, summary tables

Check the residuals, using performance::check_model(model_x)

```{r summary_tables_1, echo=TRUE}
check_model(model1)
check_model(model2)

```

As you start building models with more explanatory variables, make sure
you use car::vif(model_x) to calculate the Variance Inflation Factor
(VIF) for your predictors and determine whether you have colinear
variables. A general guideline is that a VIF larger than 5 or 10 is
large, and your model may suffer from collinearity. Remove the variable
in question and run your model again without it.

```{r summary_tables_2, echo=TRUE}

print("Model 1 Variance Inflation Factor")
vif(model1)

print("Model 2 Variance Inflation Factor")
vif(model2)

print("Summary of the new model")
model2b <- lm(log(price_4_nights) ~  number_of_reviews + review_scores_rating, data = listings)
msummary(model2b)

```

*Model1 doesn't suffer from collinearity*
*Model2 suffer from collinearity (prop_type_simplified, room_type) then we
create a new model without the two variables*

Create a summary table, using huxtable
(<https://fda-bbs.netlify.app/example/modelling_side_by_side_tables/>)
that shows which models you worked on, which predictors are significant,
the adjusted R2R2, and the Residual Standard Error.

```{r summary_tables_3, echo=TRUE}

huxreg(list("Model1" = model1, "Model2b" = model2b),
       statistics = c('Adj. R squared' = 'adj.r.squared', 
                      'Residual SE' = 'sigma'), 
       bold_signif = 0.05,
       stars = NULL) %>% 
  set_caption('Comparison of models')

```

*The variables in bold are significant predictors of the logarithm of the price for 4 night.*

## Team members

### Davide Mosezon

Born in Bologna in 1988 I'm a RFID Specialist in Lab ID Srl

### Federica Mori

I am Italian, born in Mantova in 1986. I've working within innovation
for more than 10 years. Now I'm an Innovation Manager at Confindustria
Emilia-Romagna Ricerca.

### Daniel Mota De Carvalho

I am Brazilian, and lived in different places there and Europe as well.
My background is in marketing and sales have been working in FMCG
companies for the last 20 years. Now I am challenging myself to learn
business analytics and enter a new career path.

### Virgínia Mendonça

I am Brazilian and have been living in EU the latest 10 years. I work
with database management systems, most experienced in Sql Server and
Postgres. Now adventuring myself in the data management world!
